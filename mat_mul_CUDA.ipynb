{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Трошкин_6131_CUDA.ipynb\"","provenance":[{"file_id":"1M8uGCMF6snfwHAGgpiWW5ibTXkd2Ik8T","timestamp":1634851513694}],"collapsed_sections":[],"authorship_tag":"ABX9TyMpg4BasGfUTob46U0XQHu3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7DrhRm2dFoW-"},"source":["В данной лабораторнйо работе выполнено перемножение матриц с помощью CPU, CPU с подключенным распараллеливанием. Также одним из способов является использование библиотеки Numba, позволяющая использовать CUDA для распараллеливания на GPU. \n","\n","Для CUDA мы использовали два варианта: \n","\n","1. Через глобальную память;\n","2. Через общую память.\n","\n","P.s: общая память повзоляет производить вычисления намного быстрее."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"674fBWauv4RP","executionInfo":{"status":"ok","timestamp":1635229323448,"user_tz":-240,"elapsed":54344,"user":{"displayName":"Kadaas Ismasis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixptK2krsvg6j3JY2Tdx5vVtPxynFnmKNkqkje=s64","userId":"13882203373290640748"}},"outputId":"322e44e4-6e4f-4aa9-95d2-722ce5ec50dd"},"source":["# добавляем используемые библиотеки\n","import math\n","import time\n","import numpy as np\n","from numba import cuda, jit, float64\n","import matplotlib.pyplot as plt\n","from tabulate import tabulate\n","\n","\n"," #1024, 1500, 2024, 4048, 8096\n","for k in [128, 256, 512, 1024, 1500, 2024, 4048]:\n","  #for l in [128, 256, 512, 1024]:\n","    TPB = 16 # thread per block - Определяем количество потоков в блоке \n","\n","    #N = l   \n","                   # 128/256/512/1024\n","    A = np.random.random((k, k))   #Матрицы для умножения\n","    B = np.random.random((k, k))\n","    C = np.zeros((k, k))      # результат перемножения матриц\n","\n","    #Вычисление перемножения на CPU силами самого CPU\n","\n","    def cpu_mat_mul(A, B, C):\n","            C = np.dot(A, B)\n","        \n","    start = time.time() # начало отсчёта времени выполнения программы \n","    cpu_mat_mul(A, B, C) # функция перемножения матриц средствами только CPU\n","    cpu = C            #записываем резулттат перемножения в спец.переменную\n","    #print('Перемножение на CPU:', time.time()-start)\n","\n","    # Аннтотация @jit - означет что код должен быть скомпилировать специальным образом для многопоточных вычислений на CPU\n","    @jit\n","    def cpu_mat_mul_jit(A, B, C):   # матрица перемноженная только силами CPU с многопоточностью\n","        C = np.dot(A, B)\n","\n","    start = time.time()\n","    cpu_mat_mul_jit(A, B, C)\n","    cpu_git = C\n","    #print('Перемножение на CPU с подключением многопоточности:', time.time()-start)\n","\n","    # Аннтотация @cuda.jit - означет что код должен быть скомпилировать специальным образом для многопоточных вычислений на GPU\n","\n","    # В данной функции используется наивный способ вычислений с помощью CUDA на GPU для распараллеливания вычислений\n","    @cuda.jit\n","    def mat_mul_naive_kernal(A, B, C):\n","        \n","        #Определяем текущую позицию двумерной сетки в нашей видеокарты\n","        #Это требуется для корректного выделения блоков с потоками вычисления\n","        i, j = cuda.grid(2)\n","        if i < C.shape[0] and j < C.shape[1]: #перемножение матриц\n","            summation = 0\n","            for k in range(A.shape[1]):\n","                summation += A[i, k] * B[k, j]\n","            C[i, j] = summation\n","\n","    def host_naive(A, B, C):\n","        '''host code for calling naive kernal\n","        '''\n","        d_A = cuda.to_device(A)  # отправляем наши массивы на девайс (GPU) для быстрого взаимодействия с ними\n","        d_B = cuda.to_device(B)\n","        d_C = cuda.device_array(C.shape, np.float64) #выделяем место под наш массив с размером, который задали для массива C\n","\n","        threadsperblock = (TPB, TPB) # собственно сам блок на \"кол-во нитей\" на  \"кол-во нитей\"\n","        blockspergrid_x = math.ceil(A.shape[0]/threadsperblock[0])\n","        blockspergrid_y = math.ceil(B.shape[1]/threadsperblock[1])\n","        blockspergrid = (blockspergrid_x, blockspergrid_y) # \n","\n","        mat_mul_naive_kernal[blockspergrid, threadsperblock](d_A, d_B, d_C) #Аргументы в квадратных скобках определяют размер \n","                                                                    #и форму сетки потока, а аргументы в круглых скобках соответствуют аргументам функции ядра \n","\n","        return d_C.copy_to_host()\n","\n","    start = time.time()\n","    host_naive(A, B, C)\n","    c_u_d_a_naive = C\n","    #print('Перемножение на GPU наивным способом:', time.time()-start)\n","\n","    # В данной функции используется наивный способ вычислений с помощью CUDA на GPU для распараллеливания вычислений\n","    # но с использованием общих объёмов памяти, что позволяет повысить производительность\n","\n","    @cuda.jit\n","    def mat_mul_shared_kernal(A, B, C):\n","        \n","        #Выделяем память на видеокарте\n","\n","        # Определяем массив в общей памяти\n","        # Размер и тип массивов должны быть известны во время компиляции\n","        s_A = cuda.shared.array((TPB, TPB), dtype=float64)  # выделяем на ядре GPU память для будущего массива \n","        s_B = cuda.shared.array((TPB, TPB), dtype=float64)\n","        \n","        x, y = cuda.grid(2) #Определяем текущую позицию двумерной сетки в нашей видеокарты\n","        tx = cuda.threadIdx.x  #это уникальный идентификатор потока в одномерном блоке\n","        ty = cuda.threadIdx.y\n","        bw = cuda.blockDim.x #Аналогично, это уникальный идентификатор блока в 1D-сетке\n","        bh = cuda.blockDim.y \n","        #print((x, y), (tx, ty), (bx, by), (bw, bh))\n","\n","        if x >= C.shape[0] or y >= C.shape[1]:\n","            return\n","\n","        tmp = 0\n","        for i in range(int(A.shape[1]/TPB)):\n","            #print((x, y), (tx, ty), i)\n","            s_A[tx, ty] = A[x, ty + bw*i] # записываем в каждый элемент массива на GPU элементы массива\n","            s_B[tx, ty] = B[tx + bh*i, y]\n","\n","            #Требуется чтоб все потоки завершелись одновременно, т.к. изначально они все ассинхронны \n","            cuda.syncthreads()\n","\n","            for j in range(TPB):\n","                tmp += s_A[tx, j] * s_B[j, ty]\n","\n","            cuda.syncthreads()\n","        C[x, y] = tmp # собственно наш результат\n","\n","    def host_optimized(A, B, C):\n","        '''host code for calling naive kernal\n","        '''\n","        d_A = cuda.to_device(A)  # d_ --> device\n","        d_B = cuda.to_device(B)\n","        d_C = cuda.device_array(C.shape, np.float64)\n","\n","        threadsperblock = (TPB, TPB)\n","        blockspergrid_x = math.ceil(A.shape[0]/threadsperblock[0])\n","        blockspergrid_y = math.ceil(B.shape[1]/threadsperblock[1])\n","        blockspergrid = (blockspergrid_x, blockspergrid_y)\n","\n","        mat_mul_shared_kernal[blockspergrid, threadsperblock](d_A, d_B, d_C) #Аргументы в квадратных скобках определяют размер \n","                                                                    #и форму сетки потока, а аргументы в круглых скобках соответствуют аргументам функции ядра\n","        return d_C.copy_to_host()\n","\n","    start = time.time()\n","    host_optimized(A, B, C)\n","    c_u_d_a_shared = C\n","    #print('Перемножение на GPU с общей памятью:', time.time()-start)\n","\n","    def main():\n","        #rows = []\n","        print('Матрица', k, 'на', k)\n","        start = time.time()\n","        lol_1 = cpu_mat_mul(A, B, C)\n","        kek_1 = time.time()-start\n","        \n","        print('Время выполнения вычислений на CPU:', kek_1, end='\\n')\n","          #plt.plot(k, kek_1)\n","          #print(lol_graph_1)\n","          \n","\n","        start = time.time()\n","        lol_2 = cpu_mat_mul_jit(A, B, C)\n","        kek_2 = time.time()-start\n","        print('Время выполнения вычислений на CPU Numba.jit:', kek_2, end='\\n')\n","\n","        start = time.time()\n","        lol_3 = host_naive(A, B, C)\n","        kek_3 = time.time()-start\n","        print('Время выполнения вычислений на GPU global:', kek_3, end='\\n')\n","          #print(ans)\n","          \n","        start = time.time()\n","        lol_4 = host_optimized(A, B, C)\n","        kek_4 = time.time()-start\n","        print('Время выполнения вычислений на GPU shared:', kek_4, end='\\n')\n","        print('Разница с лучшим результатом распараллеливания:', kek_1 - min(kek_2, kek_3, kek_4))\n","        print(\"-\" * 80)\n","          #print(ans)\n","          #kek = [kek_1, kek_2, kek_3, kek_4]\n","        #row = [k, kek_1, kek_2, kek_3, kek_4]\n","        #rows.append(row)\n","    #print(tabulate(rows, headers=['matrix size', 'CPU', 'CPU Numba.jit', 'GPU global', 'GPU shared']))\n","       \n","\n","    if __name__ == '__main__':\n","      main()\n","    \n","\n","    #print('Простое CPU и GPU shared::', np.allclose(cpu, c_u_d_a_shared), end='\\n\\n')\n","\n","    #print('Простое CPU с распараллеливанием и GPU shared::', np.allclose(cpu_git, c_u_d_a_shared), end='\\n\\n')\n","\n","    #print(\"Данные представлены с использованием:\", TPB,\"потоков в блоке и\", \"размерностью массивов\", k, \"на\", k, end='\\n\\n\\n\\n\\n\\n')\n","  \n","    "],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Матрица 128 на 128\n","Время выполнения вычислений на CPU: 0.004070758819580078\n","Время выполнения вычислений на CPU Numba.jit: 0.0002231597900390625\n","Время выполнения вычислений на GPU global: 0.003416776657104492\n","Время выполнения вычислений на GPU shared: 0.0028014183044433594\n","Разница с лучшим результатом распараллеливания: 0.0038475990295410156\n","--------------------------------------------------------------------------------\n","Матрица 256 на 256\n","Время выполнения вычислений на CPU: 0.004828214645385742\n","Время выполнения вычислений на CPU Numba.jit: 0.0013797283172607422\n","Время выполнения вычислений на GPU global: 0.006148338317871094\n","Время выполнения вычислений на GPU shared: 0.005535602569580078\n","Разница с лучшим результатом распараллеливания: 0.003448486328125\n","--------------------------------------------------------------------------------\n","Матрица 512 на 512\n","Время выполнения вычислений на CPU: 0.011809110641479492\n","Время выполнения вычислений на CPU Numba.jit: 0.012165307998657227\n","Время выполнения вычислений на GPU global: 0.03133797645568848\n","Время выполнения вычислений на GPU shared: 0.013492345809936523\n","Разница с лучшим результатом распараллеливания: -0.0003561973571777344\n","--------------------------------------------------------------------------------\n","Матрица 1024 на 1024\n","Время выполнения вычислений на CPU: 0.06864237785339355\n","Время выполнения вычислений на CPU Numba.jit: 0.1117854118347168\n","Время выполнения вычислений на GPU global: 0.1863243579864502\n","Время выполнения вычислений на GPU shared: 0.06852531433105469\n","Разница с лучшим результатом распараллеливания: 0.00011706352233886719\n","--------------------------------------------------------------------------------\n","Матрица 1500 на 1500\n","Время выполнения вычислений на CPU: 0.22719311714172363\n","Время выполнения вычислений на CPU Numba.jit: 0.25262999534606934\n","Время выполнения вычислений на GPU global: 0.41603565216064453\n","Время выполнения вычислений на GPU shared: 0.15021228790283203\n","Разница с лучшим результатом распараллеливания: 0.0769808292388916\n","--------------------------------------------------------------------------------\n","Матрица 2024 на 2024\n","Время выполнения вычислений на CPU: 0.5095443725585938\n","Время выполнения вычислений на CPU Numba.jit: 0.539247989654541\n","Время выполнения вычислений на GPU global: 0.9738531112670898\n","Время выполнения вычислений на GPU shared: 0.3639998435974121\n","Разница с лучшим результатом распараллеливания: 0.14554452896118164\n","--------------------------------------------------------------------------------\n","Матрица 4048 на 4048\n","Время выполнения вычислений на CPU: 3.980483293533325\n","Время выполнения вычислений на CPU Numba.jit: 3.969101905822754\n","Время выполнения вычислений на GPU global: 7.653451681137085\n","Время выполнения вычислений на GPU shared: 2.8122026920318604\n","Разница с лучшим результатом распараллеливания: 1.1682806015014648\n","--------------------------------------------------------------------------------\n"]}]}]}